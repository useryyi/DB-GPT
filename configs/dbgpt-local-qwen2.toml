[system]
# Load language from environment variable(It is set by the hook)
language = "${env:DBGPT_LANG:-zh}"
api_keys = []
encrypt_key = "your_secret_key"

# Server Configurations
[service.web]
host = "0.0.0.0"
port = 5670

[service.web.database]
type = "sqlite"
path = "pilot/meta_data/dbgpt.db"

[rag.storage]
[rag.storage.vector]
type = "chroma"
persist_path = "pilot/data"

[rag.storage.graph]
type = "tugraph"
host="192.168.128.168"
port=7687
username="admin"
password="73@TuGraph"

# Model Configurations
[models]
[[models.llms]]
# name = "Qwen2.5-Coder-0.5B-Instruct"
name = "Qwen2.5-7B-Instruct"
provider = "hf"
# If not provided, the model will be downloaded from the Hugging Face model hub
# uncomment the following line to specify the model path in the local file system
# path = "the-model-path-in-the-local-file-system"
# path = "models/Qwen2.5-Coder-0.5B-Instruct"
path = "/home/glm/work/models/Qwen/Qwen2.5-7B-Instruct"

[[models.embeddings]]
# name = "BAAI/bge-large-zh-v1.5"
name = "BAAI/bge-m3"
provider = "hf"
# If not provided, the model will be downloaded from the Hugging Face model hub
# uncomment the following line to specify the model path in the local file system
# path = "the-model-path-in-the-local-file-system"
# path = "models/BAAI/bge-large-zh-v1.5"
# path = "/home/glm/work/models/BAAI/bge-large-zh-v1.5"
path = "/home/glm/work/models/BAAI/bge-m3"

# 定义 rerank 模型配置
[[models.reranks]]
name = "BAAI/bge-reranker-v2-m3"
provider = "hf"  # 表示从 Hugging Face 加载
path = "/home/glm/work/models/BAAI/bge-reranker-v2-m3"  # 本地模型路径
device = "cuda"  # 使用 GPU（如果可用）
max_length = 512  # 最大输入长度
batch_size = 8  # 批处理大小
normalize = true  # 是否归一化输出向量